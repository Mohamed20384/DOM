import os
import io
from dotenv import load_dotenv
import streamlit as st
from PyPDF2 import PdfReader
import google.generativeai as genai
from langchain.text_splitter import CharacterTextSplitter
from langchain_google_genai import GoogleGenerativeAIEmbeddings, ChatGoogleGenerativeAI
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.runnables import RunnablePassthrough
from langchain_core.output_parsers import StrOutputParser
from langchain_community.vectorstores import FAISS
from typing import List, Dict, Tuple

# Streamlit page configuration MUST be first
st.set_page_config(
    page_title="Ù…Ø³Ø§Ø¹Ø¯ Ø§Ù„Ù…Ø·Ø§Ø¹Ù… Ø§Ù„Ù…ØµØ±ÙŠ",
    layout="wide",
    page_icon="ğŸ½ï¸",
    initial_sidebar_state="expanded"
)

# Configuration
class Config:
    CHUNK_SIZE = 1000
    CHUNK_OVERLAP = 200
    EMBEDDING_BATCH_SIZE = 10
    MAX_PREVIEW_CHARS = 5000
    PDF_FOLDER = "Restaurants"
    SYSTEM_PROMPT = """Ø£Ù†Øª (DOM) Ù…Ø³Ø§Ø¹Ø¯ Ø°ÙƒÙŠ ÙŠØªØ­Ø¯Ø« Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø§Ù„Ù…ØµØ±ÙŠØ© Ø¨Ø·Ù„Ø§Ù‚Ø©. 
    Ùˆ Ø§Ù†Øª Ù…ÙˆØ§Ø·Ù† Ù…Ù† Ù…Ø¯ÙŠÙ†Ø© Ø¯Ù…ÙŠØ§Ø· Ø§Ù„Ø¬Ø¯ÙŠØ¯Ù‡ Ù„Ø¯ÙŠÙƒ Ø®Ø¨Ø±Ù‡ ÙƒØ¨ÙŠØ±Ù‡ ÙÙŠ Ø§Ù„Ù…Ø·Ø§Ø¹Ù… ÙÙŠ Ù‡Ø°Ù‡ Ø§Ù„Ù…Ø¯ÙŠÙ†Ù‡ 
    Ø³ØªØ¬ÙŠØ¨ Ø¹Ù„Ù‰ Ø§Ù„Ø£Ø³Ø¦Ù„Ø© Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ù…ÙˆØ¬ÙˆØ¯Ø© ÙÙŠ Ù…Ø³ØªÙ†Ø¯Ø§Øª PDF Ø§Ù„Ø®Ø§ØµØ© Ø¨Ø§Ù„Ù…Ø·Ø§Ø¹Ù….
    - Ø§Ø³ØªØ®Ø¯Ù… Ù„ØºØ© Ø³Ù‡Ù„Ø© ÙˆØ¨Ø³ÙŠØ·Ø© ÙƒÙ…Ø§ ÙŠØªØ­Ø¯Ø« Ø§Ù„Ù…ØµØ±ÙŠÙˆÙ†
    - Ø¥Ø°Ø§ Ù„Ù… ØªØ¬Ø¯ Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© ÙÙŠ Ø§Ù„Ù…Ø³ØªÙ†Ø¯Ø§Øª Ù‚Ù„ "Ù…Ø¹Ù†Ø¯ÙŠØ´ Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø¯ÙŠ Ù„Ù„Ø£Ø³Ù"
    - Ø£Ø¬Ø¨ Ø¨Ø·Ø±ÙŠÙ‚Ø© ÙˆØ¯ÙŠØ© ÙˆÙ…Ø±Ø­Ø© ÙƒÙ…Ø§ ÙŠØªØ­Ø¯Ø« Ø£Ù‡Ù„ Ù…ØµØ±
    - Ø±ÙƒØ² Ø¹Ù„Ù‰ Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ø¹Ù…Ù„ÙŠØ© Ù…Ø«Ù„ Ø§Ù„Ø¹Ù†Ø§ÙˆÙŠÙ†ØŒ Ø§Ù„Ø£Ø³Ø¹Ø§Ø±ØŒ Ø§Ù„Ù…Ø£ÙƒÙˆÙ„Ø§ØªØŒ ÙˆØ§Ù„Ø®ØµØ§Ø¦Øµ Ø§Ù„Ù…Ù…ÙŠØ²Ø©"""
    UI_THEME = {
        "primary_color": "#FF4B4B",
        "secondary_color": "#FF9E9E",
        "background_color": "#0E1117",
        "text_color": "#FAFAFA",
        "success_color": "#00D100"
    }

# Custom CSS
st.markdown(f"""
<style>
:root {{
    --primary: {Config.UI_THEME['primary_color']};
    --secondary: {Config.UI_THEME['secondary_color']};
    --bg: {Config.UI_THEME['background_color']};
    --text: {Config.UI_THEME['text_color']};
    --success: {Config.UI_THEME['success_color']};
}}

.reportview-container .main .block-container {{
    direction: rtl;
    text-align: right;
    max-width: 1200px;
}}

.stChatMessage {{
    padding: 1rem;
    border-radius: 15px;
    margin-bottom: 1rem;
}}

.stChatMessage.user {{
    background-color: var(--bg);
    border: 1px solid var(--primary);
}}

.stChatMessage.assistant {{
    background-color: #1E1E1E;
    border: 1px solid var(--secondary);
}}

.stTextInput > div > div > input {{
    text-align: right;
    padding: 12px;
    border-radius: 15px;
}}

.stButton button {{
    background-color: var(--primary);
    color: white;
    border-radius: 15px;
    padding: 10px 24px;
}}

.stButton button:hover {{
    background-color: var(--secondary);
    color: white;
}}

.sidebar .sidebar-content {{
    background-color: var(--bg);
}}

.st-expander {{
    background-color: var(--bg);
    border: 1px solid var(--secondary);
    border-radius: 10px;
}}

.stAlert {{
    border-radius: 10px;
}}

.file-preview {{
    background-color: #1E1E1E;
    padding: 1rem;
    border-radius: 10px;
    margin-bottom: 1rem;
}}

.file-title {{
    color: var(--primary);
    font-weight: bold;
    margin-bottom: 0.5rem;
}}

.spinner-text {{
    color: var(--secondary);
    font-size: 1.2rem;
}}
</style>
""", unsafe_allow_html=True)

# Load environment variables
load_dotenv()
GOOGLE_API_KEY = os.getenv("GENAI_API_KEY")
genai.configure(api_key=GOOGLE_API_KEY)

# App Header
st.title("ğŸ½ï¸ Ù…Ø³Ø§Ø¹Ø¯ Ù…Ø·Ø§Ø¹Ù… Ø¯Ù…ÙŠØ§Ø· (DOM)")
st.markdown("""
<div style="text-align: right; direction: rtl;">
Ø§Ø³Ø£Ù„Ù†ÙŠ Ø£ÙŠ Ø³Ø¤Ø§Ù„ Ø¹Ù† Ø§Ù„Ù…Ø·Ø§Ø¹Ù… ÙÙŠ Ø¯Ù…ÙŠØ§Ø· Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø© ÙˆØ³Ø£Ø¬ÙŠØ¨Ùƒ Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ù…ÙˆØ¬ÙˆØ¯Ø© Ø¹Ù†Ø¯ÙŠ
</div>
""", unsafe_allow_html=True)

# Initialize session state for chat history
if "messages" not in st.session_state:
    st.session_state.messages = []
    st.session_state.messages.append({
        "role": "assistant",
        "content": "Ø£Ù‡Ù„Ø§Ù‹ ÙˆØ³Ù‡Ù„Ø§Ù‹! Ø£Ù†Ø§ Ù…Ø³Ø§Ø¹Ø¯Ùƒ Ø§Ù„Ø°ÙƒÙŠ Ù„Ù„Ù…Ø·Ø§Ø¹Ù… ÙÙŠ Ø¯Ù…ÙŠØ§Ø· Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø©. Ù…Ù…ÙƒÙ† Ø£Ø³Ø§Ø¹Ø¯Ùƒ Ø¨Ø¥ÙŠÙ‡ Ø§Ù„Ù†Ù‡Ø§Ø±Ø¯Ø©ØŸ"
    })

# Cached resources
@st.cache_resource
def get_llm():
    return ChatGoogleGenerativeAI(
        model="gemini-2.5-flash",  # Updated to newer model
        google_api_key=GOOGLE_API_KEY, 
        temperature=0.7
    )

@st.cache_resource
def get_embeddings():
    return GoogleGenerativeAIEmbeddings(
        model="models/embedding-001", 
        google_api_key=GOOGLE_API_KEY
    )

@st.cache_resource
def get_vectorstore():
    """Create and return the FAISS vectorstore"""
    documents = []
    pdf_folder = Config.PDF_FOLDER
    
    if not os.path.exists(pdf_folder):
        os.makedirs(pdf_folder)
        return None
    
    for filename in os.listdir(pdf_folder):
        if filename.lower().endswith('.pdf'):
            filepath = os.path.join(pdf_folder, filename)
            try:
                with open(filepath, "rb") as f:
                    reader = PdfReader(f)
                    text = "\n".join([page.extract_text() or "" for page in reader.pages])
                    if text.strip():
                        documents.append((filename, text))
            except Exception as e:
                st.error(f"Error processing {filename}: {str(e)}")
    
    if not documents:
        return None
    
    # Split all texts into chunks
    text_splitter = CharacterTextSplitter(
        chunk_size=Config.CHUNK_SIZE, 
        chunk_overlap=Config.CHUNK_OVERLAP
    )
    
    all_chunks = []
    for filename, text in documents:
        chunks = text_splitter.split_text(text)
        all_chunks.extend([(chunk, filename) for chunk in chunks])
    
    # Create vector store
    texts = [chunk for chunk, _ in all_chunks]
    metadatas = [{"source": filename} for _, filename in all_chunks]
    
    embeddings = get_embeddings()
    return FAISS.from_texts(
        texts=texts,
        embedding=embeddings,
        metadatas=metadatas
    ), documents

def format_docs(docs):
    """Format retrieved documents for display"""
    formatted = []
    for doc in docs:
        source = doc.metadata.get("source", "unknown")
        content = doc.page_content
        formatted.append(f"ğŸ“„ Ø§Ù„Ù…ØµØ¯Ø±: {source}\nğŸ“ Ø§Ù„Ù…Ø­ØªÙˆÙ‰:\n{content}\n{'='*50}")
    return "\n\n".join(formatted)

def get_retriever(vectorstore):
    """Create a retriever with similarity search"""
    return vectorstore.as_retriever(search_kwargs={"k": 5})

def create_rag_chain(retriever):
    """Create the RAG chain for question answering"""
    prompt = ChatPromptTemplate.from_messages([
        ("system", Config.SYSTEM_PROMPT),
        ("human", """Ø§Ù„Ø³Ø¤Ø§Ù„: {question}
        
        Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø°Ø§Øª Ø§Ù„ØµÙ„Ø©:
        {context}
        
        Ø¬Ø§ÙˆØ¨ Ø¨Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø§Ù„Ù…ØµØ±ÙŠØ©:""")
    ])
    
    return (
        {"context": retriever | format_docs, "question": RunnablePassthrough()}
        | prompt
        | get_llm()
        | StrOutputParser()
    )

# Load and process PDFs
with st.spinner("Ø¬Ø§Ø±ÙŠ ØªØ­Ù…ÙŠÙ„ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ù…Ø·Ø§Ø¹Ù…... â³"):
    result = get_vectorstore()

if not result:
    st.error("âš ï¸ Ù…ÙÙŠØ´ Ù…Ù„ÙØ§Øª PDF Ù…ÙˆØ¬ÙˆØ¯Ø© ÙÙŠ Ù…Ø¬Ù„Ø¯ Ø§Ù„Ù…Ø·Ø§Ø¹Ù…. Ø±Ø¬Ø§Ø¡ Ø¶Ø¹ Ø§Ù„Ù…Ù„ÙØ§Øª ÙÙŠ Ù…Ø¬Ù„Ø¯ 'Restaurants'")
    st.stop()

vectorstore, documents = result
retriever = get_retriever(vectorstore)
rag_chain = create_rag_chain(retriever)

# Display chat messages
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# Chat input
if question := st.chat_input("Ø§Ø³Ø£Ù„ Ø³Ø¤Ø§Ù„ Ø¹Ù† Ø§Ù„Ù…Ø·Ø§Ø¹Ù…..."):
    st.session_state.messages.append({"role": "user", "content": question})
    with st.chat_message("user"):
        st.markdown(question)
    
    with st.chat_message("assistant"):
        with st.spinner("ğŸ”Ø¨ÙÙƒØ± ..."):
            try:
                response = rag_chain.invoke(question)
                st.markdown(response)
                st.session_state.messages.append({"role": "assistant", "content": response})
            except Exception as e:
                error_msg = "âš ï¸ Ø­ØµÙ„ Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø©ØŒ Ø­Ø§ÙˆÙ„ ØªØ§Ù†ÙŠ Ø¨Ø¹Ø¯ Ø´ÙˆÙŠØ©"
                st.error(error_msg)
                st.session_state.messages.append({"role": "assistant", "content": error_msg})

# Document information sidebar
with st.sidebar:
    st.header("ğŸ“‚ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ù…Ø·Ø§Ø¹Ù… Ø§Ù„Ù…ØªØ§Ø­Ø©")
    st.markdown(f"""
    <div style="text-align: right; direction: rtl;">
    <p style="color: {Config.UI_THEME['success_color']};">Ø¹Ø¯Ø¯ Ø§Ù„Ù…Ù„ÙØ§Øª: {len(documents)}</p>
    </div>
    """, unsafe_allow_html=True)
    
    for filename, text in documents:
        with st.expander(f"ğŸ“„ {filename}", expanded=False):
            st.markdown(f"""
            <div class="file-preview">
                <div class="file-title">Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ù…Ø³ØªØ®Ø±Ø¬:</div>
                <div>{text[:Config.MAX_PREVIEW_CHARS] + ("..." if len(text) > Config.MAX_PREVIEW_CHARS else "")}</div>
            </div>
            """, unsafe_allow_html=True)
    
    st.markdown("""
    <div style="text-align: center; margin-top: 2rem; color: #888;">
    <hr>
    Ù…Ø³Ø§Ø¹Ø¯ Ø§Ù„Ù…Ø·Ø§Ø¹Ù… Ø§Ù„Ù…ØµØ±ÙŠ - Ø¥ØµØ¯Ø§Ø± 1.0
    </div>
    """, unsafe_allow_html=True)